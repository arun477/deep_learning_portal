{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b414c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import gzip, pickle, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a44711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/mnist.pkl.gz')\n",
    "with gzip.open(data_path, 'r') as f:\n",
    "    ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding='latin') \n",
    "x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130df2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "img = img.view(28, 28)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6512da",
   "metadata": {},
   "source": [
    "```python\n",
    "# simple 2 layer nn\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aab0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_o):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "69c452f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = x_train.shape[1]\n",
    "n_h = 50\n",
    "n_o = 10\n",
    "\n",
    "model = Model(n_in, n_h, n_o)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976497b",
   "metadata": {},
   "source": [
    "```python\n",
    "# cross entropy loss\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b3e3033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f55877da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897382c5",
   "metadata": {},
   "source": [
    "```python\n",
    "# log product to sum trick\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4224144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e2fb32b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3750fe",
   "metadata": {},
   "source": [
    "```python\n",
    "# log sum exp trick\n",
    "* normalize with the maximum value, so avoid exploding big activations.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ff97d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[-1]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15525034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp(x)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f162cd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1b296",
   "metadata": {},
   "source": [
    "```python\n",
    "# pytorch logsumexp function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c68dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a05b6bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cf042",
   "metadata": {},
   "source": [
    "```python\n",
    "# negative log likeliehood\n",
    "* for one hot input vector, it simplifies to the following formula.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e432942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(inp, targ):\n",
    "    return - inp[range(targ.shape[0]), targ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a76d119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0c1d3",
   "metadata": {},
   "source": [
    "```python\n",
    "# compare it with native pytorch implementation of nll.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a6341634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.nll_loss(F.log_softmax(pred, -1), y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dc174",
   "metadata": {},
   "source": [
    "```python\n",
    "# nll and softmax combined implementation.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "438279a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.cross_entropy(pred, y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0cd5a",
   "metadata": {},
   "source": [
    "```python\n",
    "# batch training.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457478a6",
   "metadata": {},
   "source": [
    "```python\n",
    "# accuracy.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d8e2c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    return (out.argmax(1)==yb).float().mean()\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0662ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0843, -0.0098,  0.1629,  0.1187,  0.1040,  0.0934, -0.1870, -0.0530,\n",
       "        -0.1361, -0.0224], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "xb = x_train[:bs]\n",
    "yb = y_train[:bs]\n",
    "preds = model(xb)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0b769d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2846, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f95d775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "00017080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb):\n",
    "    print(f\"loss: {loss:.2f}, accuracy: {accuracy(preds, yb):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7b862586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e26cc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.28, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "lr = 0.5\n",
    "epochs = 3\n",
    "xb,yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "loss = loss_func(preds, yb)\n",
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7b6640f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1b7b",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# parameters\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "081578f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1.boo = 'hey'\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "046dbed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "92234266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4626, -0.5572, -0.2930],\n",
       "         [-0.2142,  0.2954, -0.5759],\n",
       "         [-0.0873,  0.5067,  0.0329],\n",
       "         [ 0.1627,  0.2251, -0.2415]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4074,  0.0654,  0.3297, -0.2555], requires_grad=True)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4b6173ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, n_h)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(n_h, n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ee85d4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(n_in, n_h, 10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f204c186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "relu: ReLU()\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "293f587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a97f1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(i+bs, n))\n",
    "            xb,yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6d4ed5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02, accuracy: 1.00\n",
      "loss: 0.05, accuracy: 0.98\n",
      "loss: 0.03, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3475767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
