{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c521220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import gzip, pickle, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd97b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/mnist.pkl.gz')\n",
    "with gzip.open(data_path, 'r') as f:\n",
    "    ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding='latin') \n",
    "x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d335782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "img = img.view(28, 28)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed37974",
   "metadata": {},
   "source": [
    "```python\n",
    "# simple 2 layer nn\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3ffd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_o):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c11bfafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = x_train.shape[1]\n",
    "n_h = 50\n",
    "n_o = 10\n",
    "\n",
    "model = Model(n_in, n_h, n_o)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7dbd2",
   "metadata": {},
   "source": [
    "```python\n",
    "# cross entropy loss\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e2dfd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47d855eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386bcdc",
   "metadata": {},
   "source": [
    "```python\n",
    "# log product to sum trick\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2e2c4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef1141a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8e324",
   "metadata": {},
   "source": [
    "```python\n",
    "# log sum exp trick\n",
    "* normalize with the maximum value, so avoid exploding big activations.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b09af338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[-1]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b5770b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp(x)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6cabf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9f42e",
   "metadata": {},
   "source": [
    "```python\n",
    "# pytorch logsumexp function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d2f090f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "af1dc557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b2f07",
   "metadata": {},
   "source": [
    "```python\n",
    "# negative log likeliehood\n",
    "* for one hot input vector, it simplifies to the following formula.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7bd2b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(inp, targ):\n",
    "    return - inp[range(targ.shape[0]), targ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bf41fed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1faff4",
   "metadata": {},
   "source": [
    "```python\n",
    "# compare it with native pytorch implementation of nll.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee95ee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.nll_loss(F.log_softmax(pred, -1), y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce3b87",
   "metadata": {},
   "source": [
    "```python\n",
    "# nll and softmax combined implementation.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "73f72271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.cross_entropy(pred, y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a65f80",
   "metadata": {},
   "source": [
    "```python\n",
    "# batch training.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd0987",
   "metadata": {},
   "source": [
    "```python\n",
    "# accuracy.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49c1d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    return (out.argmax(1)==yb).float().mean()\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ac59be6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0843, -0.0098,  0.1629,  0.1187,  0.1040,  0.0934, -0.1870, -0.0530,\n",
       "        -0.1361, -0.0224], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "xb = x_train[:bs]\n",
    "yb = y_train[:bs]\n",
    "preds = model(xb)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "73731ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2846, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "501a930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca7403f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb):\n",
    "    print(f\"loss: {loss:.2f}, accuracy: {accuracy(preds, yb):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2fc145a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a94c0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.28, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "lr = 0.5\n",
    "epochs = 3\n",
    "xb,yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "loss = loss_func(preds, yb)\n",
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5d6564fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cf546f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3082545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
