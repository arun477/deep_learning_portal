{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2907b93",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1706.03762 (original paper) <br/>\n",
    "https://jalammar.github.io/illustrated-transformer/ (blog illustrated explanation) <br/>\n",
    "https://nlp.seas.harvard.edu/2018/04/03/attention.html (paper with annotation with code) <br/>\n",
    "https://www.youtube.com/watch?v=kCc8FmEb1nY (karpathy gpt from scratch video) <br/>\n",
    "https://github.com/karpathy/ng-video-lecture (karpathy gpt from scratch notebooks) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee46906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a8f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "block_size = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e73606",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd95e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/tinyshakespeare.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5a21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l : \"\".join(itos[c] for c in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c63458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf6570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data\n",
    "    idx = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    xs = torch.stack([data[i:i+block_size] for i in idx])\n",
    "    ys = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    xs, ys = xs.to(device), ys.to(device)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28d682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    o = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'test']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[k] = loss.item()\n",
    "        o[split] = losses.mean().item()\n",
    "    model.train()\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092db40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
