{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3200993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import gzip, pickle, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95584486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/mnist.pkl.gz')\n",
    "with gzip.open(data_path, 'r') as f:\n",
    "    ((x_train, y_train), (x_test, y_test), _) = pickle.load(f, encoding='latin') \n",
    "x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbacd8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "img = img.view(28, 28)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1be34e",
   "metadata": {},
   "source": [
    "```python\n",
    "# simple 2 layer nn\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04e28cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_o):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d4320df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = x_train.shape[1]\n",
    "n_h = 50\n",
    "n_o = 10\n",
    "\n",
    "model = Model(n_in, n_h, n_o)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab8c86",
   "metadata": {},
   "source": [
    "```python\n",
    "# cross entropy loss\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64b1a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp()/x.exp().sum(-1, keepdim=True)).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2644178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73941ae",
   "metadata": {},
   "source": [
    "```python\n",
    "# log product to sum trick\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10bf0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1, keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "24f4e10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb050ae5",
   "metadata": {},
   "source": [
    "```python\n",
    "# log sum exp trick\n",
    "* normalize with the maximum value, so avoid exploding big activations.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7b0f08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[-1]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3cde8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp(x)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "54e86d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84583044",
   "metadata": {},
   "source": [
    "```python\n",
    "# pytorch logsumexp function\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a9567e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - x.logsumexp(-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d096430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3917, -2.3172, -2.1445,  ..., -2.3604, -2.4435, -2.3298],\n",
       "        [-2.3426, -2.2119, -2.2799,  ..., -2.3664, -2.4151, -2.2220],\n",
       "        [-2.3725, -2.2966, -2.2658,  ..., -2.2858, -2.3270, -2.3698],\n",
       "        ...,\n",
       "        [-2.4004, -2.3082, -2.1309,  ..., -2.3633, -2.4319, -2.2571],\n",
       "        [-2.4322, -2.3229, -2.1224,  ..., -2.3613, -2.4487, -2.2554],\n",
       "        [-2.3660, -2.2850, -2.0563,  ..., -2.3602, -2.5124, -2.3140]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88104d",
   "metadata": {},
   "source": [
    "```python\n",
    "# negative log likeliehood\n",
    "* for one hot input vector, it simplifies to the following formula.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a6bf8185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(inp, targ):\n",
    "    return - inp[range(targ.shape[0]), targ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c253c246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred = log_softmax(pred)\n",
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a20764",
   "metadata": {},
   "source": [
    "```python\n",
    "# compare it with native pytorch implementation of nll.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1be09db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.nll_loss(F.log_softmax(pred, -1), y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f0dc3b",
   "metadata": {},
   "source": [
    "```python\n",
    "# nll and softmax combined implementation.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fc0fb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pytorch = F.cross_entropy(pred, y_train)\n",
    "loss_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c00bd",
   "metadata": {},
   "source": [
    "```python\n",
    "# batch training.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114d4f3",
   "metadata": {},
   "source": [
    "```python\n",
    "# accuracy.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c72b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    return (out.argmax(1)==yb).float().mean()\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aa303426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0843, -0.0098,  0.1629,  0.1187,  0.1040,  0.0934, -0.1870, -0.0530,\n",
       "        -0.1361, -0.0224], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 50\n",
    "xb = x_train[:bs]\n",
    "yb = y_train[:bs]\n",
    "preds = model(xb)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0982a337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2846, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b88383f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "da9481fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(loss, preds, yb):\n",
    "    print(f\"loss: {loss:.2f}, accuracy: {accuracy(preds, yb):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a4de4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "228179c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.28, accuracy: 0.14\n"
     ]
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "lr = 0.5\n",
    "epochs = 3\n",
    "xb,yb = x_train[:bs], y_train[:bs]\n",
    "preds = model(xb)\n",
    "loss = loss_func(preds, yb)\n",
    "report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c7cde0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.94\n",
      "loss: 0.13, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea8988",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# parameters\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "44c0d9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1.boo = 'hey'\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f5ac143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "08d20a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4626, -0.5572, -0.2930],\n",
       "         [-0.2142,  0.2954, -0.5759],\n",
       "         [-0.0873,  0.5067,  0.0329],\n",
       "         [ 0.1627,  0.2251, -0.2415]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4074,  0.0654,  0.3297, -0.2555], requires_grad=True)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8645e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, n_h)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(n_h, n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "12ae1cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(n_in, n_h, 10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "53a343df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "relu: ReLU()\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "43e7eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "45061c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(i+bs, n))\n",
    "            xb,yb = x_train[s], y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4c4c28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.02, accuracy: 1.00\n",
      "loss: 0.05, accuracy: 0.98\n",
      "loss: 0.03, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1dbcd",
   "metadata": {},
   "source": [
    "```python\n",
    "# nn.Module behind the scene\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1daa9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in, n_h)\n",
    "        self.l2 = nn.Linear(n_h, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith('_'):\n",
    "            self._modules[k] = v\n",
    "        \n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "21532145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True), 'relu': ReLU()}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(n_in, n_h, n_o)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ea967002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c24d7d",
   "metadata": {},
   "source": [
    "```python\n",
    "# registering modules\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "107093db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0c683a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b9b0e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{i}\", l)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "34c38762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "59f85b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31a371",
   "metadata": {},
   "source": [
    "```python\n",
    "# nn.ModuleList\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1e59438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2090e5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d63ec",
   "metadata": {},
   "source": [
    "```python\n",
    "# nn.Sequential\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ef55d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ef675c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14, accuracy: 0.96\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.05, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "28c0c0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48749588",
   "metadata": {},
   "source": [
    "```python\n",
    "# optim\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "70e358f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "13635e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a5954a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ad545e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13, accuracy: 0.96\n",
      "loss: 0.12, accuracy: 0.92\n",
      "loss: 0.08, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2b793951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2ff4166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_o))\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return opt, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9dab9451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2912, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt, model = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6536134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15, accuracy: 0.96\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.06, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c28648",
   "metadata": {},
   "source": [
    "```python\n",
    "# dataset\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ecfd7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "dee584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1dfaceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "560539a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13, accuracy: 0.96\n",
      "loss: 0.10, accuracy: 0.98\n",
      "loss: 0.12, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb,yb = train_ds[i: min(i+bs, n)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08811a0",
   "metadata": {},
   "source": [
    "```python\n",
    "# data loader\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "190d8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds, self.bs = ds, bs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4d625f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "98398e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e291c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2c80e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5f40f5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.16, accuracy: 0.96\n",
      "loss: 0.11, accuracy: 0.98\n",
      "loss: 0.07, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49f1409",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# random sampling\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6bce9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cbeef3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n, self.shuffle = len(ds), shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a42c365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8bd94d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b6a6adb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b02c3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "381e6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "04f97475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = BatchSampler(ss, 5)\n",
    "list(islice(iter(batches), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fdc22de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c99d01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, batchs, collate_fn=collate):\n",
    "        fc.store_attr()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "b68577e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_sampler = BatchSampler(Sampler(valid_ds, shuffle=True), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6fb71b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, train_sampler)\n",
    "valid_dl = DataLoader(valid_ds, valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2e85771a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(valid_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e9617a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28, 28));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4749c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt, model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2e707786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.11, accuracy: 0.94\n",
      "loss: 0.27, accuracy: 0.96\n",
      "loss: 0.03, accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a0175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
