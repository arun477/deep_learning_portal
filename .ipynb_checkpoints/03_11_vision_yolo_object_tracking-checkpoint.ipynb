{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CEDubm6B_gM",
    "outputId": "8d54c779-1777-4fcb-8ac1-2a689cbf4687",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install ultralytics\n",
    "# ! pip install fastprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2K_VFNynCgV0"
   },
   "source": [
    "https://arxiv.org/abs/1506.02640 (yolo paper) <br/>\n",
    "https://github.com/ultralytics/ultralytics (official lib, yolov8) <br/>\n",
    "https://docs.ultralytics.com/quickstart/ (official doc) <br/>\n",
    "https://www.youtube.com/@Ultralytics (official youtube channel) <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHSnfORZCwKi"
   },
   "source": [
    "https://docs.ultralytics.com/modes/track/ (live object tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NuxQOFmlCeIG"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import Video, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "spNlCGE7D6C0"
   },
   "outputs": [],
   "source": [
    "# load basic pre-trained detect model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1_pte3wZGDEr"
   },
   "outputs": [],
   "source": [
    "# input target video input\n",
    "video_path = \"./data/Amazing_Indoor_Koi_Pond.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mLMmCMb-GDG_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total frames:  500\n",
      "orignal fps:  30.0\n"
     ]
    }
   ],
   "source": [
    "# video capture is a helper function to get the frames from video file.\n",
    "# returns generator object, we can efficiently loop through get the subsequent frames.\n",
    "desired_fps = 500\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print('total frames: ', total_frames)\n",
    "print('orignal fps: ', original_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "2NI1vmS0HUWT",
    "outputId": "34666d35-28ac-46eb-9c16-49576e677eca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prediction: 500frames [01:14,  6.70frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_frames = []\n",
    "\n",
    "# setup the progress bar\n",
    "progress_bar = tqdm(total_frames, desc=\"prediction\", unit=\" frames\")\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    res, frame = cap.read()\n",
    "\n",
    "    if not res:\n",
    "        print('done!')\n",
    "        break\n",
    "    \n",
    " \n",
    "    # persist: if True current frame output will be passed to the next frame prediction\n",
    "    predictions = model.track(frame, persist=True, verbose=False)\n",
    "\n",
    "    # plot the predictions\n",
    "    # cv2.imshow(\"YOLOv8 Tracking\", predictions[0].plot())\n",
    "    \n",
    "    # store each frames\n",
    "    predicted_frames.append(predictions[0].plot())\n",
    "    \n",
    "    # updte the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # break the loop by key press.\n",
    "    # cv2.waitKey(1) wait for 1 milli second.\n",
    "    # 0xFF: & 0xFF: This is a bitwise AND operation with the hexadecimal value 0xFF (which is 255 in decimal).\n",
    "    # this operation is used to extract the least significant 8 bits (or the lowest byte) of the ASCII value.\n",
    "    # this is necessary because the return value of cv2.waitKey() can be larger than 255,\n",
    "    # and we are interested only in the lower 8 bits, which correspond to the ASCII value\n",
    "    # ord(.): integer representation of unicode character of the given character.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# destroy all the memory related to VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# any open windows like image/video display\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./output/object_tracking_v1.mp4\"\n",
    "\n",
    "frames = predicted_frames\n",
    "if not frames:\n",
    "    print(\"Error: No frames to create video.\")\n",
    "else:\n",
    "    height, width, layers = frames[0].shape\n",
    "\n",
    "    # codec with videowriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    speed = 1 # increase for make it fast\n",
    "    fps = speed*original_fps # for smoothness\n",
    "    video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # write each frame\n",
    "    for frame in frames:\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    # read to the disk\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RZt4yJF9lQBD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./output/object_tracking_v1.mp4\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html video embedding\n",
    "html_video = f\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\"\n",
    "\n",
    "# display the hmtl \n",
    "HTML(html_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
