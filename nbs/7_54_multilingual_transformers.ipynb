{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9cd096-9f41-4ac5-8b80-50a75dca4449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translations', 'talk_name'],\n",
       "    num_rows: 258098\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('ted_multi', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4d55b7-06da-42e9-be8d-b85f2f8ada2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translations': {'language': ['ar',\n",
       "   'bg',\n",
       "   'de',\n",
       "   'el',\n",
       "   'en',\n",
       "   'es',\n",
       "   'eu',\n",
       "   'fa',\n",
       "   'fr',\n",
       "   'fr-ca',\n",
       "   'he',\n",
       "   'hr',\n",
       "   'hu',\n",
       "   'it',\n",
       "   'ja',\n",
       "   'ko',\n",
       "   'nb',\n",
       "   'nl',\n",
       "   'pl',\n",
       "   'pt',\n",
       "   'pt-br',\n",
       "   'ro',\n",
       "   'ru',\n",
       "   'sq',\n",
       "   'tr',\n",
       "   'vi',\n",
       "   'zh-cn',\n",
       "   'zh-tw'],\n",
       "  'translation': ['من ضمن جميع المثبطات المقلقة التي نعاني منها اليوم نفكر في المقام الاول في الامور المالية والاقتصادية واكثر ما يهمني بشكل اكثر هو عجز الحوار السياسي — قدرتنا على فهم الصراعات الحديثة على ماهي عليه , بالذهاب الى اصلها الفعلي وعلى فهم اللاعبين الرئيسيين وعلى التعامل معهم',\n",
       "   'Наред с всички обезпокоителни дефицити , с които се сблъскваме днес - ние основно мислим за финансовите и икономическите - този , който ме безпокои най-вече е липсата на политически диалог - нашата способност да подходим към съвременните конфликти както те присъстват , да стигнем до източника на това , от което те произтичат и да разберем ключовите участници и да се разберем с тях .',\n",
       "   'Unter den schwierigen Problemen , mit denen wir heutzutage ringen – wir denken hier in erster Linie an finanzielle und ökonomische Probleme – dasjenige , das mich am meisten beunruhigt , ist der Mangel an politischem Dialog : Unsere Fähigkeit , mit modernen Konflikten umzugehen , zur ihrer eigentlichen Quelle zu gehen , die Hauptakteure zu verstehen , und mit ihnen umzugehen .',\n",
       "   'Ανάμεσα σε όλα τα ανησυχητικά ελλείμματα που αντιμετωπίζουμε σήμερα - σκεφτόμαστε το πολιτικό και οικονομικό έλλειμμα αρχικά - αυτό που με ανησυχεί περισσότερο είναι το έλλειμμα του πολιτικού διαλόγου , η ικανότητά μας να αντιμετωπίσουμε σύγχρονες συγκρούσεις όπως είναι , να πάμε στην πηγή της αιτίας τους και να καταλάβουμε τους παίκτες-κλειδιά και να τους αντιμετωπίσουμε .',\n",
       "   'Amongst all the troubling deficits we struggle with today — we think of financial and economic primarily — the ones that concern me most is the deficit of political dialogue — our ability to address modern conflicts as they are , to go to the source of what they &apos;re all about and to understand the key players and to deal with them .',\n",
       "   'De todos los déficits preocupantes a los que nos enfrentamos hoy , pensamos principalmente en el financiero y en el económico . Pero el que más me preocupa es el déficit del diálogo político , nuestra capacidad para tratar conflictos modernos tal y como son , ir a la raíz de por qué existen y entender a los actores principales y tratar con ellos .',\n",
       "   'Gaur egun aurrean ditugun gabezia kezkagarri guztietatik , nagusiki finantza eta ekonomian pentsatzen dugu , ni gehien kezkatzen nauena elkarrizketa politiko falta da ordea . Gatazka modernoak direna bezala jorratzeko gaitasuna , gatazkaren errora iristea eta aktore nagusiak ulertzea eta haiekin tratatzea .',\n",
       "   'از میان همه کاستی های نگران کننده ای که امروزه با آنها درگیریم — بیشتر اوقات ذهنمان معطوف جنبه های مالی و اقتصادی است — آنچه مرا بیش از همه نگران می کند کمبود گفتگوی سیاسی است — یعنی توانایی ما در پرداختن به درگیری های مدرن آنگونه که هستند ، در ریشه یابی آنها و شناخت و درک بازیگران کلیدی و پرداختن به آنها .',\n",
       "   'Parmi tous les déficits inquiétants contre lesquels nous luttons aujourd&apos; hui — surtout en matière économique et financière — celui qui me préoccupe le plus est le déficit du dialogue politique — notre capacité à résoudre les conflits modernes tels qu&apos; ils sont , d&apos; aller à la source de ce qu&apos; ils sont et d&apos; identifier les principaux acteurs et de traiter avec eux .',\n",
       "   'Parmi tous les déficits que nous accusons aujourd &apos; hui , et même si l &apos; on pense qu &apos; ils sont surtout d &apos; ordre financier et économique , celui qui me préoccupe le plus , c &apos; est le déficit du dialogue politique ; C &apos; est-à-dire notre capacité à gérer les conflits modernes tels qu &apos; ils sont , de pouvoir comprendre leur source même et les acteurs clés qui les composent , pour ensuite s &apos; en occuper .',\n",
       "   'מתוך מכלול הגרעונות המציקים שעמם אנחנו מתמודדים היום אנחנו חושבים בראש וראשונה על הגרעון הפיננסי והכלכלי — הגרעון שמדאיג אותי יותר מכל הוא המחסור או ההעדר בדיאלוג פוליטי — שמשפיע על היכולת שלנו להתמודד עם סכסוכים מודרניים כמו שהם , לרדת לשורש העניין , להבין מי הם השחקנים העיקריים ולהתמודד איתם .',\n",
       "   'Među svim zabrinjavajućim problemima s kojima se danas susrećemo , tu prvenstveno mislimo na ekonomske i financijske , ali oni koji me najviše zabrinjavaju nedostatci su političkog dijaloga , naše sposobnosti da se nosimo s modernim sukobima kao takvima , da doprijemo do njihove biti i da shvatimo ključne igrače te da se s njima obračunamo .',\n",
       "   'Az összes aggasztó hiány közül , amikkel ma küszködünk — — elsősorban pénzügyi és a gazdasági hiányra gondolunk — engem leginkább a politikai párbeszéd hiánya aggaszt — azé a képességünké , hogy a modern konfliktusokat , annak vegyük , amik , hogy visszamenjünk az eredetükig , amiről valójában szólnak , és hogy megértsük a kulcsszereplőket és kezeljük őket .',\n",
       "   'Tra tutti i problematici disavanzi contro i quali combattiamo oggi — principalmente pensiamo a quelli finanziari o economici — quello che mi preoccupa maggiormente è il deficit del dialogo politico — la nostra capacità di indirizzarci ai conflitti moderni nel modo in cui sono , per andare alla fonte di ciò che riguardano , per capire chi sono i giocatori chiave e per trattare con loro .',\n",
       "   '我々が今日直面している 様々な機能不全のなかで — 財政や経済が最初に思いつきますが — 私が一番 憂慮しているのは 政治的対話の欠乏です 我々が 近年の紛争において 状況を把握し その根本原因を探り 中心人物を理解し 彼らと交渉をする能力です',\n",
       "   '오늘날 우리가 겪고 있는 문제를 야기하는 모든 결핍들 중에서 우리는 주로 재정과 경제를 생각합니다만 , 제가 가장 우려하는 것들은 정치적 대화의 결핍입니다 . 우리가 현대의 갈등들을 그 자체로서 논하고 , 그 갈등들이 진정 무엇에 관한것이었는지 그 근원을 알아보고 , 그 핵심 인물들을 이해하고 , 그리고 그들을 상대하는 능력말입니다 .',\n",
       "   'Blant alle de urovekkende manglene vi strever med i dag — vi tenker primært på finansielle og økonomiske — de som bekymrer meg mest er mangelen på politisk dialog — vår evne til å adressere moderne konflikter slik de er , å finne kilden for det de egentlig handler om og å forstå nøkkelspillerne og å forholde seg til dem .',\n",
       "   'Van al onze verontrustende tekorten tegenwoordig — als eerste denk je aan financiële en economische — is het meest belangrijke voor mij het tekort aan politieke dialoog : ons onvermogen met moderne conflicten om te gaan , naar de kern te gaan en de sleutelfiguren te begrijpen , en ze aan te pakken .',\n",
       "   'Wśród problemów z jakimi zmagamy się dziś , mamy na myśli przede wszystkim te finansowe i ekonomiczne . Problemem , który mnie interesuje najbardziej jest deficyt politycznego dialogu , brak umiejętności odniesienia się do współczesnych konfliktów , dotarcia do ich źródła i zrozumienia kim są ich kluczowi gracze i jak z nimi postępować .',\n",
       "   'Entre todas as grandes privações com que nos debatemos hoje — pensamos em financeiras e económicas primeiro — aquela que mais me preocupa é a falta de diálogo político — a nossa capacidade de abordar conflitos modernos como eles são , de ir à raiz do que eles são e perceber os agentes-chave e lidar com eles .',\n",
       "   'Entre todos os déficits preocupantes com que lidamos hoje — nós pensamos principalmente nos financeiros ou econômicos — o que me preocupa mais é a falta de diálogo político — nossa habilidade de lidar com os conflitos modernos como eles são , ir à fonte do que eles tratam , entender os atores chave e lidar com eles',\n",
       "   'Printre toate deficitele îngrijorătoare cu care ne luptăm azi — ne gândim la cele financiare şi economice în primul rând — cel care mă preocupă cel mai mult este deficitul dialogului politic — abilitatea noastră de a aborda conflictele moderne aşa cum se prezintă , de a ajunge la sursa care le provoacă să înţelegem jucătorii cheie şi să le facem faţă .',\n",
       "   'Среди всех дефицитов , беспокоящих нас сегодня — прежде всего финансового и экономического — меня больше всего волнует дефицит политического диалога : нашей способности реагировать на современные конфликты в их настоящем виде , осознавать , что лежит в их основе , кто является ключевыми игроками , и как с ними работать .',\n",
       "   'Midis gjithe problemeve me deficite ne luftojme me te sotmen — ne kryesisht mendojme per financa dhe ekonomi — per te cilat shqetsohemi me shume eshte deficiti i dialogu politike — aftesia jone per te adresuar konflikte moderne ashtu sic ato jane , për të shkuar tek burimi dhe per te kuptuar lojtaret kyç dhe te merremi me ta .',\n",
       "   'Günümüzde mücadele ettiğimiz bütün eksiklikler arasında — öncelikle finansal ve ekonomik olanları düşünüyoruz — beni en çok ilgilendireni politik diyalog eksikliği — modern çatışmaları oldukları haliyle irdeleme becerimiz , varoluş nedeninin kaynağına gitmek ve kilit oyuncuları anlamak ve onlarla anlaşmak .',\n",
       "   'Trong số tất cả những thâm hụt phiền phức mà chúng ta đang phải vật lộn để vượt qua — thường thì chúng ta chủ yếu nghĩ về tài chính và kinh tế — điều khiến tôi quan tâm nhất là sự thâm hụt trong đối thoại chính trị — khả năng chúng ta giải quyết các cuộc xung đột hiện đại đúng với bản chất của chúng , để đi tới nguồn gốc của vấn đề và để hiểu những nhân vật chủ chốt trong cuộc xung đột để có cách giải quyết với họ .',\n",
       "   '当今我们与之斗争的所有不足中 大家认为经济和金融缺陷是最紧要的 但最使我担忧的 是政治对话的不足 - 包括我们处理实际上的 现代冲突的能力 ， 追溯到这些冲突问题本源的能力 ， 以及理解关键人物 ， 并与他们沟通的能力 。',\n",
       "   '在所有今日世人仍然必需去努力實現的種種令人憂心的缺點之中 — - 我們認為金融和經濟是最根本主要的 — 但是我最關心的是 是政治上對話的不足 — 我們有能力應付現今的衝突 實際上就是 ， 找到事情發生的原因 了解關鍵人物 再和他們打交道 。']},\n",
       " 'talk_name': 'jonas_gahr_store_in_defense_of_dialogue'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f81924-7612-4ca7-836a-dd2ac879240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258098/258098 [00:16<00:00, 16094.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "from tqdm import tqdm\n",
    "\n",
    "langs = ['it', 'es', 'ar', 'fr', 'de']\n",
    "train_examples = {f'en-{lang}':[] for lang in langs}\n",
    "for row in tqdm(dataset):\n",
    "    idx = row['translations']['language'].index('en')\n",
    "    source = row['translations']['translation'][idx].strip()\n",
    "    for lang in row['translations']['language']:\n",
    "        i = row['translations']['language'].index(lang)\n",
    "        if lang in langs:\n",
    "            train_examples[f'en-{lang}'].append(source + '\\t' + row['translations']['translation'][i].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9228ef83-a1e1-4ee7-8ca4-6255db81f139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-it -> 204503\n",
      "en-es -> 196026\n",
      "en-ar -> 214111\n",
      "en-fr -> 192304\n",
      "en-de -> 167888\n"
     ]
    }
   ],
   "source": [
    "for lang_pair in train_examples.keys():\n",
    "    print(lang_pair, '->', len(train_examples[lang_pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af39911e-78df-4758-8e98-27741e00f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We who are diplomats , we are trained to deal with conflicts between states and issues between states .\\tWir Diplomaten sind dazu ausgebildet worden , mit Streitigkeiten zwischen Staaten umzugehen .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[lang_pair][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abe120f6-00f9-470f-93a5-224a7f2354d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204503\n",
      "196026\n",
      "214111\n",
      "192304\n",
      "167888\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "for lang_pair in train_examples.keys():\n",
    "    with gzip.open(f'./data/ted-train-{lang_pair}.tsv.gz', 'wt', encoding='utf-8') as dest:\n",
    "        print(len(train_examples[lang_pair]))\n",
    "        dest.write('\\n'.join(train_examples[lang_pair][:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd5fa49-464c-4fac-b2bd-4c051dc45b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606038fa-be60-40df-8984-1d55e00c6b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'will', 'include', 'several', 'languages']\n",
      "['一', '[UNK]', '中', '文', '[UNK]', '[UNK]']\n",
      "['τ', '##ο', 'ε', '##λ', '##λ', '##η', '##ν', '##ι', '##κ', '##ο', 'α', '##λ', '##φ', '##α', '##β', '##η', '##τ', '##ο', 'ε', '##ι', '##ν', '##α', '##ι', 'π', '##ο', '##λ', '##υ', 'ω', '##ρ', '##α', '##ι', '##ο']\n",
      "['[UNK]', '[UNK]', '[UNK]']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'we will include several languages',\n",
    "    '一些中文单词',\n",
    "    'το ελληνικό αλφάβητο είναι πολύ ωραίο',\n",
    "    'ჩვენ გვაქვს ქართული'\n",
    "]\n",
    "\n",
    "for text in sentences:\n",
    "    print(bert_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e8af894-1b44-4205-b43e-dddf8976b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7055593d-19de-4524-93c5-5310e6df2d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁we', '▁will', '▁include', '▁several', '▁language', 's']\n",
      "['▁', '一些', '中文', '单', '词']\n",
      "['▁το', '▁ελληνικό', '▁αλ', 'φά', 'βη', 'το', '▁είναι', '▁πολύ', '▁ωραίο']\n",
      "['▁ჩვენ', '▁გვაქვს', '▁ქართული']\n"
     ]
    }
   ],
   "source": [
    "for text in sentences:\n",
    "    print(xlmr_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90429087-4136-4ce9-9c3b-1afb04f5b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "xlmr = models.Transformer('xlm-roberta-base')\n",
    "pooling = models.Pooling(\n",
    "    xlmr.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "student = SentenceTransformer(modules=[xlmr, pooling])\n",
    "student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e5ecd44-c694-4309-96f9-c120bf821dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher = SentenceTransformer('all-mpnet-base-v2')\n",
    "teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "426aa0d9-400e-4e7e-8788-31ba873e210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher = SentenceTransformer('paraphrase-distilroberta-base-v2')\n",
    "teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df058c64-0486-424e-a879-217b13d651e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import ParallelSentencesDataset\n",
    "\n",
    "data = ParallelSentencesDataset(teacher_model=teacher, student_model=student,\n",
    "                                    batch_size=32, use_embedding_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99293753-718e-462f-bacf-e465d5b78b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ted-train-en-ar.tsv.gz\n",
      "ted-train-en-de.tsv.gz\n",
      "ted-train-en-es.tsv.gz\n",
      "ted-train-en-fr.tsv.gz\n",
      "ted-train-en-it.tsv.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18608"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentences_per_language = 500000\n",
    "max_sentence_length = 250\n",
    "train_files = [f for f in os.listdir('./data') if 'train' in f]\n",
    "for train_file in train_files:\n",
    "    print(train_file)\n",
    "    data.load_data('./data/'+train_file, max_sentences=max_sentences_per_language,\n",
    "                   max_sentence_length=max_sentence_length)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62e818f6-543c-4485-8e07-6fc26d2a091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(data, batch_size=32, shuffle=True) \n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "569009a0-5440-4fca-87cf-21f3dc17437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MSELoss(model=student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bc130f0-ba66-4909-9ce3-ff44b2a20e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdca60c1d83145cfacad43ab2681dcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02626d2be11f40409f3536f580ca784f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import evaluation\n",
    "import numpy as np\n",
    "\n",
    "epochs = 1\n",
    "warmup_steps = int(len(loader)*epochs*0.1)\n",
    "\n",
    "student.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='./xmlr-ted',\n",
    "    optimizer_params={'lr': 2e-5, 'eps': 1e-6},\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d224b5d1-3061-45f0-987f-37e35854ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'similarity_score'],\n",
       "    num_rows: 1379\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "en = datasets.load_dataset('stsb_multi_mt', 'en', split='test')\n",
    "en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13f462e5-be8e-4a64-9c1b-ada86f805954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'similarity_score'],\n",
       "    num_rows: 1379\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = datasets.load_dataset('stsb_multi_mt', 'it', split='test')\n",
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2418526d-37b7-4669-af44-2ed04964a802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043bfc7e0cb641b2800734134e6cadd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc20f05dd1c3453ab1f04370cc84609f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en = en.map(lambda x: {'similarity_score': x['similarity_score'] / 5.0})\n",
    "it = it.map(lambda x: {'similarity_score': x['similarity_score'] / 5.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7f40d34-fc0c-4552-9d41-56161695c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "en_samples = []\n",
    "it_samples = []\n",
    "en_it_samples = []\n",
    "\n",
    "for i in range(len(en)):\n",
    "    en_samples.append(InputExample(\n",
    "        texts=[en[i]['sentence1'], en[i]['sentence2']],\n",
    "        label=en[i]['similarity_score']\n",
    "    ))\n",
    "    it_samples.append(InputExample(\n",
    "        texts=[it[i]['sentence1'], it[i]['sentence2']],\n",
    "        label=it[i]['similarity_score']\n",
    "    ))\n",
    "    en_it_samples.append(InputExample(\n",
    "        texts=[en[i]['sentence1'], it[i]['sentence2']],\n",
    "        label=en[i]['similarity_score']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8f8de05-a9fa-44fb-a82d-be2bff3b788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "en_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    en_samples, write_csv=False\n",
    ")\n",
    "it_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    it_samples, write_csv=False\n",
    ")\n",
    "en_it_eval = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    en_it_samples, write_csv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b038634-65a6-46b4-856d-cae42952b09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20577197595832455"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('./xmlr-ted')\n",
    "\n",
    "en_eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c177cef8-edc6-4a17-ad08-5219c117c484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23425532464366874"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "557f5012-419f-46db-b316-7a1eb47099a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1036000454584871"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_it_eval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9a4449a-0f1d-464e-9f25-675451d7c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import models\n",
    "\n",
    "xlmr = models.Transformer('xlm-roberta-base')\n",
    "pooler = models.Pooling(\n",
    "    xlmr.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "\n",
    "student = SentenceTransformer(modules=[xlmr, pooler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bda96ca4-6737-4b59-82ea-416427b5e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47525931826733264"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_eval(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ea36fd1-7113-4b96-b004-6a77eac52123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4963748045018903"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_eval(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e04ad64c-aa47-4783-acac-3af4a291ee56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2297664675626828"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_it_eval(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07835720-b92c-46bc-b8ee-64b16882e705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
