{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d78675",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1312.6114.pdf (vae paper)<br/>\n",
    "https://docs.google.com/presentation/d/1FkkhH86URDzAzjNPdCvupV6kqoBNNarVQQgB6ppZlx4/edit#slide=id.g26890724310_0_7 (latent variable models lecture notes) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf431f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import default_collate, DataLoader\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc52e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mnist (/Users/arun/.cache/huggingface/datasets/mnist/mnist/1.0.0/9d494b7f466d6931c64fb39d58bb1249a4d85c9eb9865d9bc20960b999e2a332)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13746669b38c46368ab785ef4c0869ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(b):\n",
    "    b['image'] = [TF.to_tensor(o) for o in  b['image']]\n",
    "    return  b\n",
    "\n",
    "def collate_dict(b):\n",
    "    c = default_collate(b)\n",
    "    return (c['image'], c['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0df633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset['train'].with_transform(transform_data)\n",
    "valid_ds = dataset['test'].with_transform(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133029a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_dict)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size*2, shuffle=False, collate_fn=collate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019508db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25, 1, 28, 28]), torch.Size([25]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[10][0]);\n",
    "plt.axis('off');\n",
    "print(yb[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc294e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=90):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.stride = 2\n",
    "        self.kernel_size = 3\n",
    "        self.padding = self.kernel_size//2\n",
    "        \n",
    "        self.enc = nn.Sequential(*[\n",
    "            nn.Conv2d(1, 8, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, self.latent_dim)\n",
    "        ]) \n",
    "        \n",
    "        self.dec = nn.Sequential(*[])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.enc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b910f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (enc): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "    (11): Linear(in_features=64, out_features=90, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad08f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 90])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(xb)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c334f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f30e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
