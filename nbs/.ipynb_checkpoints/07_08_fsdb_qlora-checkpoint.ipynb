{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2af0f4",
   "metadata": {},
   "source": [
    "https://github.com/AnswerDotAI/fsdp_qlora/blob/main/train.py (ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes\n",
    "# !pip install hqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2152b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from typing import List, Dict, Union\n",
    "import torch\n",
    "from torch import nn\n",
    "from bitsandbytes.nn import Linear4bit\n",
    "\n",
    "try:\n",
    "    from hqq.core.quantize import HQQLinear, HQQBackend, BaseQuantizeConfig\n",
    "except ImportError:\n",
    "    HQQLinear = None\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ca42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f413142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c267bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self, args, log_to='stdout', project_name='fsdp_qlora',\n",
    "                 entity=None, group=None, name=None, rank=0):\n",
    "        self.log_to = log_to\n",
    "        if self.log_to == 'wandb' and rank==0:\n",
    "            import wandb\n",
    "            wandb.init(\n",
    "                project=project_name,\n",
    "                entity=entity,\n",
    "                group=group,\n",
    "                name=name,\n",
    "                cofig=args\n",
    "            )\n",
    "    \n",
    "    def log(self, d:Dict, rank:int):\n",
    "        if rank != 0:\n",
    "            return \n",
    "        if self.log_to == \"tqdm\":\n",
    "            for k,v in d.items():\n",
    "                tqdm.write(f'{k}: {v}')\n",
    "        elif self.log_to == 'wandb':\n",
    "            wandb.log(d)\n",
    "        elif self.log_to == 'stdout':\n",
    "            for k,v in d.item():\n",
    "                print(f'{k}: {v}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress_bar(progress_bar:tqdm, epoch:int, log_loss:float, log_lr:float, rank:int):\n",
    "    if rank==0:\n",
    "        if log_lr >= 0:\n",
    "            progress_bar.set_description(f\"epoch {epoch}, loss {log_loss:.3f}, lr {log_lr:.2e}\", refresh=True)\n",
    "        else:\n",
    "            progress_bar.set_description(f\"epoch {epoch}, loss {log_loss:.3f}\", refresh=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear(model:nn.Module, linear_replacement:nn.Module, quant_config:Union[dict,None]=None,\n",
    "                  skip_modules:List[str]=['lm_head'], **kwargs):\n",
    "    for name, module in model.named_children():\n",
    "        if len(list(module.children())) > 0:\n",
    "            replace_linear(module, linear_replacement, quant_config, skip_modules, **kwargs)\n",
    "            \n",
    "        if isinstance(module, nn.Linear) and name not in skip_modules:\n",
    "            if issubclass(linear_replacement, Linear4bit):\n",
    "                model._modules[name] = linear_replacement(\n",
    "                    module.in_features,\n",
    "                    module.out_features,\n",
    "                    module.bias is not None,\n",
    "                    **kwargs\n",
    "                )\n",
    "            elif issubclass(linear_replacement, HQQLinear):\n",
    "                model._modules[name] = linear_replacement(module, quant_config, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"unsupported linear replacement: {type(linear_replacement)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f78096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Linear(5, 10),\n",
    "    nn.Sequential(nn.Linear(10, 50), nn.ReLU())\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b2e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5]) torch.float32\n",
      "torch.Size([10]) torch.float32\n",
      "torch.Size([50, 10]) torch.float32\n",
      "torch.Size([50]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in m.parameters():\n",
    "    print(p.shape, p.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ff371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear4bit(in_features=5, out_features=10, bias=True)\n",
       "  (1): Sequential(\n",
       "    (0): Linear4bit(in_features=10, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = replace_linear(m, linear_replacement=Linear4bit) \n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfe736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5]) torch.float32\n",
      "torch.Size([10]) torch.float32\n",
      "torch.Size([50, 10]) torch.float32\n",
      "torch.Size([50]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for p in r.parameters():\n",
    "    print(p.shape, p.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a75365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d84514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
