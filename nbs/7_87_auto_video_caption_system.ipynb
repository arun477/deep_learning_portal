{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "u4AKoXCU5yPy"
   },
   "outputs": [],
   "source": [
    "# !pip install ffmpeg-python datasets evaluate jiwer gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhfxxVkg6qjW",
    "outputId": "d07bf640-51e2-4367-a2d4-01483c49a10c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_id = 'openai/whisper-small'\n",
    "model = pipeline('automatic-speech-recognition', model=model_id, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Vk8y6IEe6B6J"
   },
   "outputs": [],
   "source": [
    "model_conf = {\n",
    "    'max_new_tokens': 258,\n",
    "    'generate_kwargs': {'task': 'transcribe'},\n",
    "    'chunk_length_s': 8,\n",
    "    'batch_size': 64,\n",
    "    'return_timestamps': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "XCLQDsqf9d9N"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_took(f):\n",
    "  def timed_f(*args, **kwargs):\n",
    "    start = time.time()\n",
    "    output = f(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    print(f'{f.__name__} took: {end-start:.3f} secs')\n",
    "    print('----------')\n",
    "    return output\n",
    "  return timed_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "cmcL-yFK72IQ"
   },
   "outputs": [],
   "source": [
    "@time_took\n",
    "def predict(audio, config=model_conf):\n",
    "  predictions = model(audio.copy(), **config)\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "8Bry0cPS76az"
   },
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import uuid\n",
    "\n",
    "@time_took\n",
    "def extract_audio_from_video(video_file):\n",
    "  start = time.time()\n",
    "  input_stream = ffmpeg.input(video_file)\n",
    "  audio = input_stream.audio\n",
    "  temp_audio_file = f'temp_{uuid.uuid4()}.mp3'\n",
    "  ffmpeg.output(audio, temp_audio_file).run()\n",
    "  return temp_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dVtjoxDx77v0"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "@time_took\n",
    "def convert_audio_to_array(audio_path):\n",
    "  audio_arr, sr = librosa.load(audio_path, sr=16_000)\n",
    "  return audio_arr, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "2-MJoqbx9DFa"
   },
   "outputs": [],
   "source": [
    "def format_time_in_iso8601(secs):\n",
    "  hrs = int(secs // 3600)\n",
    "  mins = int((secs % 3600) // 60)\n",
    "  secs = secs % 60\n",
    "  return f\"{hrs:02d}:{mins:02d}:{secs:06.3f}\"\n",
    "\n",
    "@time_took\n",
    "def text_to_vtt(prediction_chunks, output_file):\n",
    "  lang = 'en'\n",
    "  with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(f'WEBVTT\\nKind: captions\\nLanguage: {lang}\\n')\n",
    "    for caption in prediction_chunks:\n",
    "      start_time = format_time_in_iso8601(caption['timestamp'][0])\n",
    "      end_time = format_time_in_iso8601(caption['timestamp'][1])\n",
    "      text = caption['text']\n",
    "      f.write(f'{start_time} --> {end_time}\\n')\n",
    "      f.write(f'{text}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "kVXwcXc_HEmN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "@time_took\n",
    "def remove_temp_audio_file(audio_file):\n",
    "  if os.path.exists(audio_file):\n",
    "    os.remove(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "k4uwFco59y9I"
   },
   "outputs": [],
   "source": [
    "@time_took\n",
    "def create_video_caption(video_file, output_file):\n",
    "  audio_path = extract_audio_from_video(video_file)\n",
    "  audio_arr, sr = convert_audio_to_array(audio_path)\n",
    "  remove_temp_audio_file(audio_path)\n",
    "  predictions = predict(audio_arr)\n",
    "  text_to_vtt(predictions['chunks'], output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Epe-3WT_C7t5"
   },
   "outputs": [],
   "source": [
    "video_file = 'Halves and fourths _ Geometry _ Early Math _ Khan Academy-0lSTXtwPuOU.mp4'\n",
    "output_file = 'caption_en.vtt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-f6ViJ5FDVeS",
    "outputId": "74057cb0-8a20-450b-8e19-f5e9f3635ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_audio_from_video took: 2.704 secs\n",
      "----------\n",
      "convert_audio_to_array took: 0.467 secs\n",
      "----------\n",
      "remove_temp_audio_file took: 0.001 secs\n",
      "----------\n",
      "predict took: 6.304 secs\n",
      "----------\n",
      "text_to_vtt took: 0.001 secs\n",
      "----------\n",
      "create_video_caption took: 9.479 secs\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "create_video_caption(video_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "OYCPEd6UMg9h",
    "outputId": "e97e3b43-e9c7-4a18-9bb5-4651486d949e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://5431ae4fb5706fa3fb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5431ae4fb5706fa3fb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def genereate_caption(video_file):\n",
    "  caption_file = 'caption_en_test.vtt'\n",
    "  create_video_caption(video_file, caption_file)\n",
    "  return video_file, caption_file\n",
    "\n",
    "demo = gr.Interface(genereate_caption, gr.Video(),\n",
    "                                     gr.Video(\n",
    "    height=300,\n",
    "    width=600,\n",
    "    ), submit_btn='Create Caption', allow_flagging='never')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.launch(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oJ6wnWBeFN_A"
   },
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# def play_video(video_file, caption_file):\n",
    "#   def play():\n",
    "#     return (video_file, caption_file)\n",
    "\n",
    "#   demo = gr.Interface(play, None, gr.Video(height=300, width=600), submit_btn='Play',\n",
    "#                       allow_flagging='never')\n",
    "\n",
    "#   if __name__ == '__main__':\n",
    "#     demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "m11XmbyYIt1H"
   },
   "outputs": [],
   "source": [
    "# play_video(video_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
