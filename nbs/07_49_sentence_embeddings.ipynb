{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f90c5d3-620d-4990-b075-4a8968566b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f8e8e9-d029-4e31-b8c4-ba21fda127b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649a19ba-edbf-4293-8ded-77b76f08c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: tensor([[0.6973]]) The weather today is beautiful\n",
      "score: tensor([[0.5133]]) It's raining!\n",
      "score: tensor([[0.1889]]) Dogs are awesome\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"The weather today is beautiful\", \"It's raining!\", \"Dogs are awesome\"]\n",
    "embeddings = model.encode(sentences)\n",
    "query_embedding = model.encode(\"today is sunny day!\")\n",
    "\n",
    "for sentence, emb in zip(sentences, embeddings):\n",
    "    score = util.pytorch_cos_sim(query_embedding, emb)\n",
    "    print(f\"score: {score}\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68982d03-84e7-4fc9-ba49-f4f43067f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = {\n",
    "    \"How do I get a replacement Medicare card?\": \"If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\",\n",
    "    \"How do I sign up for Medicare?\": \"If you already get Social Security benefits, you do not need to sign up for Medicare. We will automatically enroll you in Original Medicare (Part A and Part B) when you become eligible. We will mail you the information a few months before you become eligible.\",\n",
    "    \"What are Medicare late enrollment penalties?\": \"In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\",\n",
    "    \"Will my Medicare premiums be higher because of my higher income?\": \"Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\",\n",
    "    \"What is Medicare and who can get it?\": \"Medicare is a health insurance program for people age 65 or older. Some younger people are eligible for Medicare including people with disabilities, permanent kidney failure and amyotrophic lateral sclerosis (Lou Gehrig’s disease or ALS). Medicare helps with the cost of health care, but it does not cover all medical expenses or the cost of most long-term care.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6625b4-acb4-421f-a077-8fc3b8a28853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:0.46, query: Will my Medicare premiums be higher because of my higher income?, answer: Some people with higher income may pay a larger percentage of their monthly Medicare Part B and prescription drug costs based on their income. We call the additional amount the income-related monthly adjustment amount.\n",
      "\n",
      "score:0.14, query: What is Medicare and who can get it?, answer: Medicare is a health insurance program for people age 65 or older. Some younger people are eligible for Medicare including people with disabilities, permanent kidney failure and amyotrophic lateral sclerosis (Lou Gehrig’s disease or ALS). Medicare helps with the cost of health care, but it does not cover all medical expenses or the cost of most long-term care.\n",
      "\n",
      "score:0.13, query: What are Medicare late enrollment penalties?, answer: In most cases, if you don’t sign up for Medicare when you’re first eligible, you may have to pay a higher monthly premium. Find more information at https://faq.ssa.gov/en-us/Topic/article/KA-02995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_embeddings = model.encode(list(faq.keys()))\n",
    "query_emb = model.encode('do i have to pay more after my raise?')\n",
    "similarities = util.semantic_search(query_emb, corpus_embeddings, top_k=3)\n",
    "\n",
    "for i, res in enumerate(similarities[0]):\n",
    "    id, score = res['corpus_id'], res['score']\n",
    "    query =  list(faq.keys())[id]\n",
    "    answer = faq[query]\n",
    "    print(f\"score:{score:.2f}, query: {query}, answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fe6caf-a3d0-445f-8aec-ad5b6f478198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4bfbfd-7496-488f-904b-84aa0fe6d417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423a7331-2d88-47fa-8f54-814d8885463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'the', 'king', 'and', 'the', 'queen', 'are', 'happy', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = 'The king and the queen are happy.'\n",
    "tokens = tokenizer.tokenize(text, add_special_tokens=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c49bda6-8618-42b8-b463-8b7b61be597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(output['last_hidden_state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967e38c5-bdc7-4ff1-aa73-4c78bd72c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (king vs queen): 0.7920710444450378\n",
      "similarity (king vs happy): 0.5239198207855225\n"
     ]
    }
   ],
   "source": [
    "king_emb = output['last_hidden_state'][0][2]\n",
    "queen_emb = output['last_hidden_state'][0][5]\n",
    "happy_emb = output['last_hidden_state'][0][7]\n",
    "\n",
    "print(f'similarity (king vs queen): {util.pytorch_cos_sim(king_emb, queen_emb)[0][0]}')\n",
    "print(f'similarity (king vs happy): {util.pytorch_cos_sim(king_emb, happy_emb)[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7808e6a5-7078-4372-83ea-80da3583ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "text = \"The angry and unhappy king\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output  = model(**encoded_input)\n",
    "print(output['last_hidden_state'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace88842-d1e9-424f-bc15-9c6ab73e695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'the', 'angry', 'and', 'unhappy', 'king', '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6166f162-0bc8-4e6a-96d3-c12e0becb9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity (king1 vs king2): 0.574000895023346\n"
     ]
    }
   ],
   "source": [
    "king2_emb = output['last_hidden_state'][0][5]\n",
    "print(f'similarity (king1 vs king2): {util.pytorch_cos_sim(king_emb, king2_emb)[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d37cda-84da-4f06-bfc3-53bbc85a8ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', '##ization']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('tokenization'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7620cd-1aee-469b-95ff-3c315bb77a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '<', 'html', '>', '<', '/', 'html', '>', '[SEP]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text =\"\"\"\n",
    "<html>\n",
    "</html>\n",
    "\"\"\"\n",
    "tokenizer.tokenize(text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb5fd70-9afd-44f0-a924-0c85f557131b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = 'this is about tokenization'\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034ad323-8a8e-469b-9c74-639be2596ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'this', 'is', 'about', 'token', '##ization', '[SEP]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cedb0f3-098d-42dd-a990-0f8cd9f4fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token_indices = [4, 5]\n",
    "word_embeddings = output['last_hidden_state'][0, word_token_indices]\n",
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12616879-77a4-442c-b9e4-220d285dd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "word_embeddings = torch.mean(word_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "201708ce-47e7-4d85-a75b-70bcf8d7462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2023, 2003, 2055, 19204, 3989]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09c0b443-83b1-437f-9259-0854d99f35ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19204, 3989]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('tokenization', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4a7d7af-a71a-44ec-b831-3667ec9ec3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(text, word):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    word_ids = tokenizer.encode(word, add_special_tokens=False)\n",
    "    word_indices = [i for i, token_id in enumerate(encoded_input['input_ids'][0]) if token_id in word_ids]\n",
    "    word_embeddings = output['last_hidden_state'][0, word_indices]\n",
    "    return torch.mean(word_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1213ec6e-40b2-4094-b1d4-7e9619e3b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "word_embeddings2 = get_word_embedding(text, 'tokenization')\n",
    "print(word_embeddings2.shape)\n",
    "print(torch.allclose(word_embeddings, word_embeddings2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efd2397-4170-45b2-a108-7612debaa6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8564]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.pytorch_cos_sim(\n",
    "    get_word_embedding('the king is angry', 'king'),\n",
    "    get_word_embedding('the queen is angry', 'queen')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64bea021-44aa-46d8-8181-27371adb17a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8059]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.pytorch_cos_sim(\n",
    "    get_word_embedding('the king is angry', 'king'),\n",
    "    get_word_embedding('the queen is happy', 'queen')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07a14fa-df4a-4736-b45b-36d8a3e24df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"this is an example sentence\", return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "cls_embedding = output['last_hidden_state'][:, 0, :]\n",
    "sentence_embedding = cls_embedding\n",
    "print(sentence_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a01a8ae-f158-41e1-9bf7-e8717e61ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output['last_hidden_state'][:, 0, :]\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    return cls_pooling(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c74c103-6174-47cb-8111-2928685064f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(get_sentence_embedding('this is an example sentence').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b772993c-f7c8-424c-bada-cbb826f6331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9317]]): The weather today is beautiful\n",
      "tensor([[0.8939]]): It's raining!\n",
      "tensor([[0.9162]]): Dogs are awesome\n"
     ]
    }
   ],
   "source": [
    "embeddings = [get_sentence_embedding(sentence) for sentence in sentences]\n",
    "query_embedding = get_sentence_embedding(\"today is sunny day\")\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    score = util.pytorch_cos_sim(query_embedding, embedding)\n",
    "    print(f\"{score}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1af8ecbc-b6ef-4a82-b017-9f86c6af010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9759]], grad_fn=<MmBackward0>): The weather today is beautiful\n",
      "tensor([[0.9329]], grad_fn=<MmBackward0>): It's raining!\n",
      "tensor([[0.8674]], grad_fn=<MmBackward0>): Dogs are awesome\n"
     ]
    }
   ],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model.pooler(model_output['last_hidden_state'])\n",
    "\n",
    "embeddings = [get_sentence_embedding(sentence) for sentence in sentences]\n",
    "query_embedding = get_sentence_embedding(\"today is sunny day\")\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    score = util.pytorch_cos_sim(query_embedding, embedding)\n",
    "    print(f\"{score}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d914d4df-c4a5-416e-a341-4b197ad4541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "455b0b0e-1b69-4f59-978b-2a57301e840d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"today is a sunny day\", return_tensors='pt')\n",
    "model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ddf2ed-cabe-49c4-83b0-fa1d411b2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = model_output['last_hidden_state']\n",
    "print(token_embeddings.shape)\n",
    "mean_embeddings = torch.mean(token_embeddings, dim=1)\n",
    "print(mean_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ec0b2d7-ca09-4906-9aa5-4e0b2ab75c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def mean_pooling(model_output):\n",
    "    return torch.mean(model_output['last_hidden_state'], dim=1)\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    meam_embeddings = mean_pooling(model_output)\n",
    "    return F.normalize(mean_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a506a54d-2cfd-45e7-a94f-248b49e27103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_embedding('today is a sunny day').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02b5652d-7e3e-49db-94e7-97ebdeddba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 384])\n",
      "torch.Size([1, 7])\n",
      "torch.Size([1, 7, 384])\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings.shape)\n",
    "attention_mask = encoded_input['attention_mask']\n",
    "print(attention_mask.shape)\n",
    "attention_mask_expanded = (\n",
    "    attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    ")\n",
    "print(attention_mask_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4053c61-4e93-457d-9d8b-99e547c90afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "print(attention_mask_expanded.sum(1).shape)\n",
    "print(token_embeddings.sum(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d8d2293-a654-49b7-ac63-c7f3ee5b6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output['last_hidden_state']\n",
    "    attention_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return token_embeddings.sum(1)/torch.clamp_min(attention_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "    sentence_embeddings = mean_pooling(model_output, attention_mask)\n",
    "    return F.normalize(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae9e9739-e393-424c-acbc-faf54f965ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0163,  0.1041,  0.0974,  0.0742,  0.0375])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding = get_sentence_embedding(\"today is a sunny day\")[0]\n",
    "query_embedding[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdb9a8e4-ecb7-4b4c-a46f-79c52058ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7190]]): The weather today is beautiful\n",
      "tensor([[0.3898]]): It's raining!\n",
      "tensor([[0.1043]]): Dogs are awesome\n"
     ]
    }
   ],
   "source": [
    "embeddings = [get_sentence_embedding(sentence) for sentence in sentences]\n",
    "query_embedding = get_sentence_embedding(\"today is sunny day\")\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    score = util.pytorch_cos_sim(query_embedding, embedding)\n",
    "    print(f\"{score}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dbd98bb-e156-4525-b4a8-5195794e6812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7344]]): The weather today is beautiful\n",
      "tensor([[0.4180]]): It's raining!\n",
      "tensor([[0.1060]]): Dogs are awesome\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "query_embedding = model.encode('today is a sunny day')\n",
    "embeddings = model.encode(sentences)\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    score = util.pytorch_cos_sim(query_embedding, embedding)\n",
    "    print(f\"{score}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f97ddc4b-b094-4dce-a012-bec426f29da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86a64154-0d7a-46f3-8c28-cec6fe461218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee8a6af5-4131-40d5-a01a-5966d951c00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'is_duplicate'],\n",
       "    num_rows: 404290\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('quora')['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79c3c8d6-c0c2-499c-82ff-25549aab5811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537362\n"
     ]
    }
   ],
   "source": [
    "corpus_questions = []\n",
    "for d in dataset:\n",
    "    corpus_questions.append(d['questions']['text'][0])\n",
    "    corpus_questions.append(d['questions']['text'][1])\n",
    "corpus_questions = list(set(corpus_questions))\n",
    "print(len(corpus_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32243a2a-6606-4612-8e01-5e537bb23cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a37b3452c614990a1e263e1dc742441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('quora-distilbert-multilingual')\n",
    "question_to_emb = 100000\n",
    "corpus_embeddings = model.encode(\n",
    "    corpus_questions[:question_to_emb],\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2bbc3b5-7742-4fea-85ec-333003273a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def search(query):\n",
    "    s_t = time.time()\n",
    "    query_emb = model.encode(query, convert_to_tensor=True)\n",
    "    res = util.semantic_search(query_emb, corpus_embeddings)\n",
    "    e_t = time.time()\n",
    "    print(f'time taken: {e_t-s_t:.3f}')\n",
    "    for result in res[0][:5]:\n",
    "        print(f\"score:{result['score']} ({corpus_questions[result['corpus_id']]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fd125e7-b340-4060-830d-fc2d30333ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.013\n",
      "score:0.9490418434143066 (How do I apply machine learning to business?)\n",
      "score:0.9449212551116943 (Where do I start learning Machine Learning?)\n",
      "score:0.9441931843757629 (How do I start learning machine learning?)\n",
      "score:0.944168210029602 (How can I teach myself machine learning?)\n",
      "score:0.9387003183364868 (How can machine learning be used?)\n"
     ]
    }
   ],
   "source": [
    "search('how can i learn Machine Learning online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f853696-af52-476e-9f47-99861fb87d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.012\n",
      "score:0.9532554745674133 (Where do I start learning Machine Learning?)\n",
      "score:0.9529364705085754 (How do I apply machine learning to business?)\n",
      "score:0.951837956905365 (How do I start learning machine learning?)\n",
      "score:0.9497791528701782 (How can I teach myself machine learning?)\n",
      "score:0.9473681449890137 (Can a person with no Coding knowledge learn Machine learning?)\n"
     ]
    }
   ],
   "source": [
    "search('Como puedo aprender Machine Learning online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21419cae-bceb-4808-9305-7ad1bc10e288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
