{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4a5302-e20d-40a9-8309-e272d921e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd3a794-e97a-4aa4-875e-fd1dbb5af70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        tokens = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(tokens)-max_length, stride):\n",
    "            input_chunk = tokens[i:i+max_length]\n",
    "            target_chunk = tokens[i+1:i+1+max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4fa9b9-70e4-4842-9c73-cf635ce66334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(txt, max_length=256, stride=128, batch_size=4, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDataset(txt, tokenizer=tokenizer, max_length=max_length, stride=stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94f3153-97b1-4490-853c-600ddc72c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, 'd_out should be divisable by num_heads'\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.w_key(x)\n",
    "        queries = self.w_query(x)\n",
    "        values = self.w_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_score = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_score.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_score/keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1179eff2-cacf-4d14-99a0-361481d5ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x = (x-mean)/torch.sqrt(var + self.eps)\n",
    "        return self.scale * x + self.shift\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37ab775-d5cc-42d1-987b-e69d773e1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7350a00b-ae70-430a-bf51-c900fbe04c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e7be40-a0da-407b-81bf-6c92409a62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            qkv_bias=cfg['qkv_bias'],\n",
    "            num_heads=cfg['n_heads']\n",
    "        )\n",
    "        self.ffn = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_resd = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.drop_resd(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.drop_resd(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe36f11-cf11-43d4-a11a-58c061a86707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch, seq_len = in_idx.shape\n",
    "        tok_embeddings = self.tok_emb(in_idx)\n",
    "        pos_embeddings = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeddings + pos_embeddings\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68f8027-7e0a-496a-b8cc-c3968766bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_length):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_length:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd88d4f-cfe7-4570-80b7-9f92e4e2f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8487184-5f6c-4a86-8b99-1f718d18029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55659bae-97ee-4637-8eb6-e7dd6d0fac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I'am\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "encoded = tokenizer.encode(start_context)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb173177-072d-4691-9281-c333ea046394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   314,     6,   321, 25646, 21652,  4803,  8058,    39,\n",
      "          6842, 37891, 23487,  7434, 42266]])\n",
      "torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=10,\n",
    "    context_length=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd895943-ee99-4ba3-9f2c-26707022c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'am restoring185house retireH bear confidently 480osit Cot\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25435f4f-1c63-4e1b-a3cf-8d16bf86dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(idx, tokenizer):\n",
    "    flat = idx.squeeze(0).tolist()\n",
    "    return tokenizer.decode(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11d92f15-d0d6-480e-8e91-02e478c7c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      " Every efforts moves you sleevesork FIGHT\"))iscKEN Instruct calling attendcipled\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "start_context = \"Every efforts moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    context_length=GPT_CONFIG_124M['context_length'],\n",
    "    max_new_tokens=10\n",
    ")\n",
    "print('output:\\n', token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ca36e4-3e60-42f2-ab81-5d96c1549342",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [588,  428,  11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08496552-8f42-491f-8848-64fd850cefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bf0b04a-7e62-4649-9610-a516256472e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: every effort moves\n",
      "target:  effort moves you\n",
      "output: orously UR loaded\n",
      "-------\n",
      "context: I really like\n",
      "target:  like this chocolate\n",
      "output:  Launcherstaَ\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "for i, o_b in enumerate(token_ids):\n",
    "    print('context:', token_ids_to_text(inputs[i], tokenizer))\n",
    "    print('target:', token_ids_to_text(targets[i], tokenizer))\n",
    "    print('output:', token_ids_to_text(o_b.flatten(), tokenizer))\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fce8b67-b8bb-47c1-b7b4-b01cf48c7e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9628e-05, 1.8337e-05, 1.9197e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(target_probs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e5a7d6-9c07-4adb-a854-8bf8ac95c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0798e-05, 2.9370e-05, 3.4076e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c732878-7af9-496b-93a5-7fcec99ea8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9628e-05, 1.8337e-05, 1.9197e-05, 4.0798e-05, 2.9370e-05, 3.4076e-05])\n"
     ]
    }
   ],
   "source": [
    "log_probs = torch.cat((target_probs_1, target_probs_2))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12176b8a-5662-4894-a6a3-6cf5283fdcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0234e-05)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probs = log_probs.mean()\n",
    "print(avg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14a286ec-03a2-485b-96b7-25fcecf1cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.0234e-05)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probs = avg_log_probs * -1\n",
    "print(neg_avg_log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "991364ed-7ebf-432d-bf78-6113b398a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape torch.Size([2, 3, 50257])\n",
      "targets.shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print('logits.shape', logits.shape)\n",
    "print('targets.shape', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd3cb7ef-3953-4741-acbf-02e78d22eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.flatten(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeb4383e-a940-4c9c-a92c-de7221626998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_flat.shape torch.Size([6, 50257])\n",
      "targets_flat.shape torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print('logits_flat.shape', logits_flat.shape)\n",
    "print('targets_flat.shape', targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "115ee5b6-da62-41ee-a3aa-e9d4454831f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(10.4554)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dd8119e-d13d-4349-b28e-c387745abd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity tensor(34733.0586)\n"
     ]
    }
   ],
   "source": [
    "perplexity = loss.exp()\n",
    "print('perplexity', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f85d70b1-8525-47d7-b1df-47101593d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as res:\n",
    "        text_data = res.read().decode('utf-8')\n",
    "    with open(file_path, 'w', encoding='utf-8') as dest:\n",
    "        dest.write(text_data)\n",
    "else:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22f9986f-6c01-4ceb-bdcf-e1280ac7393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap g\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cb455ad-ec25-423a-8d25-5a922061d29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars 20479\n",
      "total tokens 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print('total chars', total_characters)\n",
    "print('total tokens', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "261d16cb-59b7-49f9-a75e-fbda537226d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride =GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M['context_length'],\n",
    "    stride =GPT_CONFIG_124M['context_length'],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcbd1a06-e809-44df-a76a-e1d4167395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print('not enough token for the training loader')\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M['context_length']:\n",
    "    print('not enough token for the validation loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde883eb-7567-4213-b943-a3cfa48aaaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print('train loader')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print('validation loader')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a8cb079-2809-423e-a39f-c4fd153509a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tokens 4608\n",
      "validation tokens 512\n",
      "all tokens 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for inp_batch, target_batch in train_loader:\n",
    "    train_tokens += inp_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for inp_batch, target_batch in val_loader:\n",
    "    val_tokens += inp_batch.numel()\n",
    "\n",
    "print('train tokens', train_tokens)\n",
    "print('validation tokens', val_tokens)\n",
    "print('all tokens', train_tokens+val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8e4829e-8ea7-4c1b-8f04-0089c673f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0215637f-df3b-4888-ad11-cfc61c6d0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71e9ccda-6030-46f2-bc27-d1422c7960c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7872b200-43c5-45d7-ab31-6f7dfdbdc35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 10.9794\n",
      "validation loss 10.9890\n"
     ]
    }
   ],
   "source": [
    "model.to(device);\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print('train loss', f\"{train_loss:.4f}\")\n",
    "print('validation loss', f\"{val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a7e5b89-6a85-464c-b34f-3edb9795b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_length=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                      eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"ep {epoch+1} (step {global_step:06d}): \" \n",
    "                     f\"train loss {train_loss:.3f}, val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e94e424e-6f63-4f01-82db-998f05764858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1 (step 000000): train loss 9.821, val loss 9.934\n",
      "ep 1 (step 000005): train loss 8.065, val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "ep 2 (step 000010): train loss 6.620, val loss 7.051\n",
      "ep 2 (step 000015): train loss 6.046, val loss 6.601\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "ep 3 (step 000020): train loss 5.570, val loss 6.481\n",
      "ep 3 (step 000025): train loss 5.516, val loss 6.401\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "ep 4 (step 000030): train loss 5.098, val loss 6.353\n",
      "ep 4 (step 000035): train loss 4.967, val loss 6.379\n",
      "Every effort moves you, and a, and a, and a-- the picture. Gisburn, and a was, and a. I had been. of the of the of the of the a of the of the of the of the of the of the of\n",
      "ep 5 (step 000040): train loss 4.356, val loss 6.261\n",
      "Every effort moves you, I had the of the picture--as he had been the of the of the of the picture of the picture of the of the man of the picture--as of the picture.   \"I had been the honour of the picture of\n",
      "ep 6 (step 000045): train loss 3.967, val loss 6.204\n",
      "ep 6 (step 000050): train loss 3.470, val loss 6.189\n",
      "Every effort moves you know the \"Oh, and--I had the fact.               \"I, and I had been the donkey.            \n",
      "ep 7 (step 000055): train loss 3.493, val loss 6.197\n",
      "ep 7 (step 000060): train loss 2.713, val loss 6.147\n",
      "Every effort moves you know the picture to have been the Riviera he had been.               \"I he was his pictures-c.             \n",
      "ep 8 (step 000065): train loss 2.246, val loss 6.142\n",
      "ep 8 (step 000070): train loss 1.919, val loss 6.214\n",
      "Every effort moves you know,\" was one of the picture.  \"I had the last word.          \"I turned, and I looked up at my elbow and I saw that, and down the room, I had\n",
      "ep 9 (step 000075): train loss 1.544, val loss 6.214\n",
      "ep 9 (step 000080): train loss 1.217, val loss 6.274\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had not that he had been--and here are the cigars you like.\"  \"Oh, as his pictures--the quality of Jack's \"There were days when I\n",
      "ep 10 (step 000085): train loss 0.924, val loss 6.320\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context='Every effort moves you', tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9674c-d7f6-47be-8221-680e25cbb2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d72c11-7cc6-49af-a6d5-b1160195b185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
