{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/learn/audio-course/en/chapter4/fine-tuning (ref) <br/> \n",
    "https://huggingface.co/carlfeynman/carl-distilhubert-finetuned-gtzan (finetuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install gradio\n",
    "# !pip install accelerate -U\n",
    "\n",
    "# !pip install soundfile\n",
    "# !pip install librosa\n",
    "# !pip install evaluate\n",
    "\n",
    "# !pip install transformers -U\n",
    "\n",
    "# !pip install --upgrade huggingface_hub\n",
    "# !pip install -U gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration all\n",
      "Reusing dataset gtzan (/root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/701395d625fb4762c27eef42c9488d843cc15869b399f7d207b07306a8b09762)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d042eff4a434656a0c429d677f6532b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\")\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/701395d625fb4762c27eef42c9488d843cc15869b399f7d207b07306a8b09762/cache-7848c6527387a015.arrow and /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/701395d625fb4762c27eef42c9488d843cc15869b399f7d207b07306a8b09762/cache-9b9f134c24d517c8.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan  = gtzan['train'].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       "  'array': array([ 0.10720825,  0.16122437,  0.28585815, ..., -0.22924805,\n",
       "         -0.20629883, -0.11334229], dtype=float32),\n",
       "  'sampling_rate': 22050},\n",
       " 'genre': 7}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = gtzan['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_fn = gtzan['train'].features['genre'].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label_fn(example['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22050,\n",
       "  array([ 0.00521851,  0.00061035,  0.0043335 , ..., -0.0149231 ,\n",
       "         -0.01800537, -0.02783203], dtype=float32)),\n",
       " 'country')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_audio():\n",
    "  example = gtzan['train'].shuffle()[0]\n",
    "  audio = example['audio']\n",
    "  return  (\n",
    "      audio['sampling_rate'],\n",
    "      audio['array']\n",
    "  ), id2label_fn(example['genre'])\n",
    "\n",
    "sample_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks() as demo:\n",
    "#   with gr.Column():\n",
    "#     for _ in range(4):\n",
    "#       audio, label = sample_audio()\n",
    "#       output = gr.Audio(audio, label=label)\n",
    "# demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ntu-spml/distilhubert\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = gtzan.cast_column('audio', Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       "  'array': array([ 0.0873509 ,  0.20183384,  0.4790867 , ..., -0.18743178,\n",
       "         -0.23294401, -0.13517427], dtype=float32),\n",
       "  'sampling_rate': 16000},\n",
       " 'genre': 7}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/pop/pop.00098.wav',\n",
       " 'array': array([ 0.0873509 ,  0.20183384,  0.4790867 , ..., -0.18743178,\n",
       "        -0.23294401, -0.13517427], dtype=float32),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = gtzan['train'][0]['audio']\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.000 var: 0.049\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean: {np.mean(audio['array']):.3f} var: {np.var(audio['array']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.000 var: 1.000\n"
     ]
    }
   ],
   "source": [
    "inputs = feature_extractor(audio['array'], sampling_rate=audio['sampling_rate'])\n",
    "print(f\"mean: {np.mean(inputs['input_values']):.3f} var: {np.var(inputs['input_values']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0\n",
    "\n",
    "def preprocess_audio(examples):\n",
    "  audio_arr = [ele['array'] for ele in examples['audio']]\n",
    "  inputs = feature_extractor(\n",
    "      audio_arr,\n",
    "      sampling_rate = feature_extractor.sampling_rate,\n",
    "      max_length = int(feature_extractor.sampling_rate*max_duration),\n",
    "      turncation = True,\n",
    "      return_attention_mask = True\n",
    "  )\n",
    "  return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/701395d625fb4762c27eef42c9488d843cc15869b399f7d207b07306a8b09762/cache-317fb56431c4abe1.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/701395d625fb4762c27eef42c9488d843cc15869b399f7d207b07306a8b09762/cache-142a76ce28440c40.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'input_values', 'attention_mask'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'input_values', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan_encoded = gtzan.map(preprocess_audio, remove_columns=[\"audio\", \"file\"],\n",
    "          batched=True, batch_size=100, num_proc=1)\n",
    "gtzan_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_values', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")\n",
    "gtzan_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blues',\n",
       " 'classical',\n",
       " 'country',\n",
       " 'disco',\n",
       " 'hiphop',\n",
       " 'jazz',\n",
       " 'metal',\n",
       " 'pop',\n",
       " 'reggae',\n",
       " 'rock']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan_encoded['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {\n",
    "    str(i): id2label_fn(i) for i in range(len(gtzan_encoded['train'].features['label'].names))\n",
    "}\n",
    "label2id = {l:i for i,l in  id2label.items()}\n",
    "id2label['7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7214e06c082f40539d83d9f62a262fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_id.split('/')[-1]\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"carl-{model_name}-finetuned-gtzan\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    "    dataloader_num_workers=5,\n",
    "    dataloader_prefetch_factor=5,\n",
    "    report_to=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "  return metric.compute(predictions=preds, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [565/565 06:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.794400</td>\n",
       "      <td>1.720942</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.224700</td>\n",
       "      <td>1.185684</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>0.969656</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.741800</td>\n",
       "      <td>0.860538</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.769503</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory carl-distilhubert-finetuned-gtzan/checkpoint-113 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=565, training_loss=1.2444716554827395, metrics={'train_runtime': 424.6266, 'train_samples_per_second': 10.586, 'train_steps_per_second': 1.331, 'total_flos': 3.0785066831834835e+17, 'train_loss': 1.2444716554827395, 'epoch': 5.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=gtzan_encoded[\"train\"],\n",
    "    eval_dataset=gtzan_encoded[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"marsyas/gtzan\",\n",
    "    \"dataset\": \"GTZAN\",\n",
    "    \"model_name\": f\"carl-{model_name}-finetuned-gtzan\",\n",
    "    \"finetuned_from\": model_id,\n",
    "    \"tasks\": \"audio-classification\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/carlfeynman/carl-distilhubert-finetuned-gtzan/commit/b80472f6c6b9299202836814223b3f78b1a64363', commit_message='End of training', commit_description='', oid='b80472f6c6b9299202836814223b3f78b1a64363', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
